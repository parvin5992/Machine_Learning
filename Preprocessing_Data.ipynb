{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xK9TFUoKXYm0",
        "kQHJdDaRRKH8",
        "ikUjpKomR-m8",
        "jaT97T89ZKs4",
        "VJcb9LPUZQip",
        "TU63UR-UaJOr",
        "0xDA7jqhby9F",
        "RUqQASh-c1dI",
        "pM0_UJW9fVbx",
        "ljcDL_DugqdO",
        "j3xJywSci0fb",
        "lt39TWGvlBWV",
        "9HbF08oHrLDp",
        "nFTtgv-34o5e",
        "ujm7yNqL5mkq",
        "WrfexKLF6_fH",
        "C8gnLLjj7oOf",
        "eDVkGgSAC60v",
        "2Ecm3ylBKrbO"
      ],
      "authorship_tag": "ABX9TyO53/EICWFwvn3tbi/k2erW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ehsan74814/Preprocessing_Data/blob/main/Preprocessing_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7wcFuH9Q9vs"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "xK9TFUoKXYm0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "EQJjbEkfXdLw"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection\n"
      ],
      "metadata": {
        "id": "kQHJdDaRRKH8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Obtain data from reliable sources, such as datases, websites or CSV files, .."
      ],
      "metadata": {
        "id": "ikUjpKomR-m8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) read file Or load the Data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/preprocessing data/Data.csv\")\n",
        "df = pd.DataFrame(df)"
      ],
      "metadata": {
        "id": "oSrlpiURSNjd"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exploration and Understanding"
      ],
      "metadata": {
        "id": "jaT97T89ZKs4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## View Data Structure"
      ],
      "metadata": {
        "id": "VJcb9LPUZQip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Use df.head() or df.info() to undertand the data types and look at the first few rows and.\n",
        "\n",
        "# df.head() # df.head(10)\n",
        "# df.info()\n",
        "# df.tail()  #df.tail(10)\n",
        "# df.sample()  # df.sample(10)\n",
        "# df.index\n",
        "# df.attrs\n",
        "# df.value_counts()\n",
        "# df[\"Age\"].value_counts().idxmax()\n",
        "# df[\"Age\"].value_counts().max()\n",
        "# df.values\n",
        "# df.dtypes\n",
        "# df.axes\n",
        "# df.empty\n",
        "# df.nunique()   # df.;;;;.nunique()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd4sDzfznKzn",
        "outputId": "f6be94ce-c1a3-40e0-cfc1-27453d888587"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Desceiptive Statistics"
      ],
      "metadata": {
        "id": "TU63UR-UaJOr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Use df.describe() to get summary statistics\n",
        "# df.describe()\n",
        "\n",
        "\n",
        "### Specify mean, mode ...\n",
        "# df[\"Age\"].mean()"
      ],
      "metadata": {
        "id": "ar4MiJsqbv3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify the number of rows and columns"
      ],
      "metadata": {
        "id": "0xDA7jqhby9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ### Use df.shape to access number of rows and columns\n",
        "df.shape"
      ],
      "metadata": {
        "id": "XX5PuO4Icz2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify the name of the column header"
      ],
      "metadata": {
        "id": "RUqQASh-c1dI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Use df.column to get name of the column header\n",
        "df.columns"
      ],
      "metadata": {
        "id": "e-XIB8xrfT8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rename columns"
      ],
      "metadata": {
        "id": "pM0_UJW9fVbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Use rename function\n",
        "df.rename(columns={'Age': 'age'}, inplace=False)"
      ],
      "metadata": {
        "id": "4FSHWFfigclx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Delete a column or a row"
      ],
      "metadata": {
        "id": "ljcDL_DugqdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use drop for column\n",
        "# df = df.drop(\"Age\", axis=1)"
      ],
      "metadata": {
        "id": "5sWxTfmchQya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use drop for row\n",
        "df = df.drop(0, axis=0)"
      ],
      "metadata": {
        "id": "gf0BNHfthUGb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## add a column"
      ],
      "metadata": {
        "id": "j3xJywSci0fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding a new column with constant values\n",
        "# df[\"M\"] = 10  or np.nan\n",
        "\n",
        "\n",
        "# adding a column based on an existing column\n",
        "# df[\"upper_name\"] = df['Country'].apply(lambda x : x.upper())\n",
        "\n",
        "# adding a column with a list or Series\n",
        "# df[\"new_column\"] = [0,1,2,0,0,0,1,1,0]"
      ],
      "metadata": {
        "id": "WO7iBEf3i6LY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## add a row"
      ],
      "metadata": {
        "id": "lt39TWGvlBWV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adding a new row  using loc[]\n",
        "# df.loc[len(df)] = [\"Iran\", 54.0, 52000, \"Yes\"]\n",
        "# df.loc[5:] = [\"Iran\", 54.0, 52000, \"Yes\"]\n",
        "# df.loc[:] = [\"Iran\", 54.0, 52000, \"Yes\"]\n",
        "# df.loc[8:4] = [\"Iran\", 54.0, 52000, \"Yes\"]\n",
        "#  با این روش فقط به ابتدا و انتها مستوان اضافه کرد\n",
        "\n",
        "\n",
        "# adding a new row with using concat()\n",
        "# new_data = pd.DataFrame({\"Country\":[\"Dubai\"],\t\"Age\":[39.0], \"Salary\":[96000.0],\t\"Purchased\":[\"Yes\"]})\n",
        "# df = pd.concat([df, new_data], ignore_index=True)\n",
        "\n",
        "\n",
        "\n",
        "# adding a new row with appenf() function\n",
        "# new_data = pd.DataFrame({\"Country\":[\"Usa\"],\t\"Age\":[45.0], \"Salary\":[10000.2],\t\"Purchased\":[\"No\"]})\n",
        "# df = df._append(new_data, ignore_index=True)\n",
        "\n",
        "\n",
        "# adding a new row with nan\n",
        "# new_row = pd.Series([np.nan]*len(df.columns), index=df.columns)\n",
        "# df = df._append(new_row, ignore_index=True)"
      ],
      "metadata": {
        "id": "4b3iOqFSq0ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Handling Missing Value"
      ],
      "metadata": {
        "id": "9HbF08oHrLDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## identify missing value"
      ],
      "metadata": {
        "id": "nFTtgv-34o5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identify missing value on row\n",
        "# df.isna().sum(axis=1)\n",
        "# df.isnull().sum(axis=1)\n",
        "\n",
        "\n",
        "\n",
        "# identify missing value on column\n",
        "# df.isna().sum(axis=0)\n",
        "# df.isnull().sum(axis=0)"
      ],
      "metadata": {
        "id": "FAd8jMvV4_Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify the row that are completely empty\n"
      ],
      "metadata": {
        "id": "ujm7yNqL5mkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify the number of rows that are completely empty\n",
        "# df.isna().all(axis=1).sum()\n",
        "# df.isnull().all(axis=1).sum()\n",
        "\n",
        "\n",
        "\n",
        "# show index row that are completely empty\n",
        "# df.index[df.isna().all(axis=1)].tolist()"
      ],
      "metadata": {
        "id": "SlBSaVh36u_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### imputation or removal"
      ],
      "metadata": {
        "id": "WrfexKLF6_fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# delet the row that are completely empty\n",
        "# df.dropna(how=\"all\")\n",
        "\n",
        "\n",
        "# filling the NaN on column with value\n",
        "# df[\"Purchased\"] = df[\"Purchased\"].fillna(\"No\")\n",
        "\n",
        "\n",
        "# filling the NaN on column with mean, mode, median\n",
        "# df[\"Age\"] = df[\"Age\"].fillna(df[\"Age\"].mean())\n"
      ],
      "metadata": {
        "id": "cWh4nk477je4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning"
      ],
      "metadata": {
        "id": "C8gnLLjj7oOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# identify duplicated\n",
        "# df.duplicated().sum()\n",
        "\n",
        "\n",
        "# show the row that are duplicated\n",
        "# df.index[df.duplicated(keep=False)].tolist()\n",
        "\n",
        "\n",
        "\n",
        "# remove duplicated\n",
        "# df.drop_duplicates()"
      ],
      "metadata": {
        "id": "Xnw_fRCQBbm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identifying outliers"
      ],
      "metadata": {
        "id": "eDVkGgSAC60v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The first way is to use Z-score for normal distribution\n",
        "# z_score = stats.zscore(df[\"Age\"])\n",
        "# outliners = df[(z_score > 3) | (z_score <-3)]\n",
        "\n",
        "\n",
        "\n",
        "# The second way is to use IQR for abnormal distribution\n",
        "# q1 = df[\"Age\"].quantile(0.25)\n",
        "# q3 = df[\"Age\"].quantile(0.75)\n",
        "# IQR = q3 - q1\n",
        "# outliners = df[(df[\"Age\"] < (q1 - 1.5 * IQR)) | (df[\"Age\"] > (q3 + 15 * IQR))]\n",
        "\n",
        "\n",
        "\n",
        "# # The third way is to use Boxplot\n",
        "# plt.figure(figsize=(8,6))\n",
        "# sns.boxplot(x=df[\"Age\"])\n",
        "# plt.title(\"Boxplot for age\")\n",
        "# plt.xlabel(\"Age\")\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# when you identify outlier you can delete row or filling values"
      ],
      "metadata": {
        "id": "eKGsa7GUENRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Transformation"
      ],
      "metadata": {
        "id": "2Ecm3ylBKrbO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify a column that has two format\n",
        "# df_string = df[\"Age\"].apply(lambda x : isinstance(x, str))\n",
        "\n",
        "\n",
        "# delet Noise\n",
        "# pd.to_numeric(df[\"Age\"],  errors=\"coerce\")\n",
        "\n",
        "# convert astype a column\n",
        "# df[\"Age\"] = df[\"Age\"].astype(str)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kiQ1UMvRKvrm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Scaling**"
      ],
      "metadata": {
        "id": "ruWYX3NUhGbh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Normalization**"
      ],
      "metadata": {
        "id": "ocmU16BxOCQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# به معنی تبدیل داده ها به مقیاس و محدوده ای مشخص . بازه صفر تا یک. برای زمانی که داده ها با مقباس های متفاوت هستند.\n",
        "\n",
        "# The first way\n",
        "# use max_min\n",
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# scaler = MinMaxScaler()\n",
        "# scaler.fit_transform(data)\n",
        "\n",
        "\n",
        "# Max Abs Scaling\n",
        "\n",
        "\n",
        "\n",
        "#Logarithm scaling\n",
        "\n",
        "\n",
        "\n",
        "# z-score NOrmalization\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X9iczTW0dPz4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Standardlization**"
      ],
      "metadata": {
        "id": "9Yb7rHcsdq5T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# استانداردسازی داده ها به معنی مقیاس بندی داده ها به نحوی که میانگین داده ها برابر صفر و انحراف معیار برابر یک است. برای زمانی\n",
        "# که داده ها با مقیاس های متفاوت باشد.\n",
        "# مزایا:\n",
        "# 1- .کاربرد در مدل های حساس مانند رگرسون لجستیک، اس وی ام، کی ان ان که به مقیاس داده ها حساس هستند.\n",
        "#2 - برای داده ها به صورت تقریبی توزیع نرمال دارند عالی است.\n",
        "#3 - در الگوریتم های مانند گرادیان نزولی، استاندارسازی داده ها باعث تسریع روند یادگیری  میشود.\n",
        "\n",
        "\n",
        "# from sklearn.preprocessing import StandardScaler\n",
        "# scaler = StandardScaler()\n",
        "# scaler.fit_transform(data)\n",
        "\n",
        "\n",
        "# در حالتی که داده های پرت داریم از زیر استفاده کنیم.\n",
        "# scaler = RobustScaler()"
      ],
      "metadata": {
        "id": "BcCzwE2kdwWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Encoding Categorical Variable**\n",
        "\n"
      ],
      "metadata": {
        "id": "i0poM-tNi9aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# one-hot Encoding\n",
        "# یک روش رایج برای تبدیل داده های دسته ای به شکل عددی است\n",
        "# categorical data\n",
        "\n",
        "# # first way with pandas\n",
        "# # pd.get_dummies(df, columns=[\",,,,\"])\n",
        "\n",
        "\n",
        "# #second way with sklearn\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "# encoder = OneHotEncoder(sparse=False)\n",
        "# encoded_data = encoder.fit_transform(df[\",,,\"])\n",
        "\n",
        "# #for better showing\n",
        "# pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out[\",,,\"])\n",
        "\n",
        "\n",
        "\n",
        "# label-encoding\n",
        "# برای تبدیل داده های دسته ای به عددی. یک عدد منحصر\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# encoder = LabelEncoder()\n",
        "# encoder.fit_transform(df[\",,\"])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Discretizatoion\n",
        "# فرایندی که در ان داده های پیوسته به طور مدام تغییر میکنند به دسته های گسسته تبدیل شود\n",
        "#first way with pandas\n",
        "# pd.cut(df[\",,,\"], bins= , labels=[])\n",
        "\n",
        "\n",
        "#second way with sklearn\n",
        "# from sklearn.preprocessing import KBinsDiscretizer\n",
        "# KBinsDiscretizer(n_bins=  , encode= \"ordinal\", strategy=\"uniform\")"
      ],
      "metadata": {
        "id": "ikyMyzCajGYI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}